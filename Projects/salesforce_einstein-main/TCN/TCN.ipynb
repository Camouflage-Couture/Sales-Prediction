{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uFHEWHvjrCa"
   },
   "source": [
    "**Inbuild libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WR25H0FYnkO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchmetrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Scve4eJMj0Rw"
   },
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set an experiment for version control\n",
    "mlflow.set_experiment('TCN Experiment 1')\n",
    "# Load the dataset\n",
    "data = pd.read_csv('../Dataset/superstore-orders.csv')\n",
    "\n",
    "# Define the target variable\n",
    "data['Sales_per_Customer'] = data['Sales per Customer']\n",
    "\n",
    "# Add lag Features for 'Sales per Customer' column\n",
    "for lag in range(1, 11):  # Sales per Customer data from 1 to 10 rows ago\n",
    "    data[f'sales_per_customer_lag_{lag}'] = data['Sales per Customer'].shift(lag)\n",
    "\n",
    "# Add rolling statistics features for 'Sales per Customer' column\n",
    "data['sales_per_customer_rolling_mean_7'] = data['Sales per Customer'].rolling(window=7).mean()\n",
    "data['sales_per_customer_rolling_std_7'] = data['Sales per Customer'].rolling(window=7).std()\n",
    "data['sales_per_customer_rolling_mean_30'] = data['Sales per Customer'].rolling(window=30).mean()\n",
    "data['sales_per_customer_rolling_std_30'] = data['Sales per Customer'].rolling(window=30).std()\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "data = pd.get_dummies(data, columns=['Category', 'Sub-Category'], drop_first=True)\n",
    "\n",
    "# Handle missing values created by lag/rolling features\n",
    "data.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Drop original Sales per Customer column to avoid redundancy\n",
    "data.drop(columns=['Sales per Customer'], inplace=True)\n",
    "\n",
    "# Display first few rows after feature engineering\n",
    "print(data.head())\n",
    "\n",
    "# Save to CSV after feature engineering\n",
    "data.to_csv('../Dataset/engineered_superstore_orders.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwSJl75WAS6f"
   },
   "source": [
    "**Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Dataset/engineered_superstore_orders.csv\")\n",
    "\n",
    "print(data.describe())\n",
    "\n",
    "X = data.drop(columns=['Sales_per_Customer'])\n",
    "y = data['Sales_per_Customer'] # target\n",
    "\n",
    "# Ensure all columns are numeric\n",
    "X = pd.DataFrame(X).apply(pd.to_numeric, errors='coerce').values\n",
    "y = pd.Series(y).apply(pd.to_numeric, errors='coerce').values\n",
    "\n",
    "# Handle missing values if any\n",
    "X = np.nan_to_num(X, nan=0.0)\n",
    "y = np.nan_to_num(y, nan=0.0)\n",
    "\n",
    "# visualizing distributions of target variables and features\n",
    "sns.histplot(y, kde=True)\n",
    "plt.show()\n",
    "\n",
    "# correlation matrix\n",
    "columns = ['Profit per Order','Quantity','Sales','Sales_per_Customer']\n",
    "corr_matrix = data[columns].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# box plot for outliers\n",
    "data[columns].plot(kind='box', subplots=True, layout=(1, len(columns)), sharex=False, sharey=False, figsize=(15, 5))\n",
    "plt.show()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#convert data into tensor format\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# channel dimension for conv1d\n",
    "X_train = X_train.unsqueeze(1)\n",
    "X_test = X_test.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLOb3suKAI3d"
   },
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qTwIEjgAKP7"
   },
   "outputs": [],
   "source": [
    "class TCN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size, dropout):\n",
    "        super(TCN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(num_inputs, num_channels, kernel_size, padding=(kernel_size-1))\n",
    "        self.conv2 = nn.Conv1d(num_channels, num_channels, kernel_size, padding=(kernel_size-1))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Calculate the size after convolution\n",
    "        self._calculate_conv_output_shape(num_inputs, kernel_size, padding=(kernel_size-1))\n",
    "        self.fc = nn.Linear(self.conv_output_size, 1)\n",
    "\n",
    "    def _calculate_conv_output_shape(self, num_inputs, kernel_size, padding):\n",
    "        # Calculate the output shape after the convolution layers\n",
    "        dummy_input = torch.zeros(1, num_inputs, X_train.size(2))\n",
    "        dummy_output = self.conv2(self.conv1(dummy_input))\n",
    "        self.conv_output_size = dummy_output.numel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "num_channels = 64\n",
    "kernel_size = 2\n",
    "dropout = 0.2\n",
    "model = TCN(num_inputs=1, num_channels=num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.1,              # Learning rate\n",
    "    betas=(0.9, 0.999),   # Coefficients for running averages\n",
    "    eps=1e-8,             # Small constant for numerical stability\n",
    "    weight_decay=1e-5,    # Weight decay (L2 penalty)\n",
    "    amsgrad=True          # Use AMSGrad variant\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training using MLflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLFlow run\n",
    "\n",
    "with mlflow.start_run(run_name='Experiment 1 - Test Run 5') as run:\n",
    "    mlflow.log_param(\"num_channels\", num_channels)\n",
    "    mlflow.log_param(\"kernel_size\", kernel_size)\n",
    "    mlflow.log_param(\"dropout\", dropout)\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs.squeeze(), y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "            mlflow.log_metric('loss', loss.item(), step=epoch+1)\n",
    "\n",
    "    # saving the model\n",
    "    mlflow.pytorch.log_model(model,'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_id=run.info.run_id):\n",
    "    model.eval()\n",
    "    # Disable gradient calculation for evaluation\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test).squeeze()\n",
    "\n",
    "    # Calculate metrics\n",
    "        # Initialize the metrics\n",
    "        mse_metric = torchmetrics.MeanSquaredError()\n",
    "        mae_metric = torchmetrics.MeanAbsoluteError()\n",
    "        rmse_metric = torchmetrics.MeanSquaredError(squared=False)  # RMSE is the square root of MSE\n",
    "        r2_metric = torchmetrics.R2Score()\n",
    "        evs_metric = torchmetrics.ExplainedVariance()\n",
    "\n",
    "        # Compute metrics\n",
    "        mse = mse_metric(predictions, y_test).item()\n",
    "        mae = mae_metric(predictions, y_test).item()\n",
    "        rmse = rmse_metric(predictions, y_test).item()\n",
    "        r2 = r2_metric(predictions, y_test).item()\n",
    "        evs = evs_metric(predictions, y_test).item()\n",
    "\n",
    "        mlflow.log_metric('MSE', mse)\n",
    "        mlflow.log_metric('MAE', mae)\n",
    "        mlflow.log_metric('RMSE', rmse)\n",
    "        mlflow.log_metric('r2', r2)\n",
    "        mlflow.log_metric('Explained_Variance_Score', evs)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f'MSE: {mse:.4f}')\n",
    "        print(f'MAE: {mae:.4f}')\n",
    "        print(f'RMSE: {rmse:.4f}')\n",
    "        print(f'R-squared: {r2:.4f}')\n",
    "        print(f'Explained Variance Score: {evs:.4f}')\n",
    "\n",
    "        # Plot actual vs predicted values with different colors\n",
    "        plt.figure(figsize=(14, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(y_test.numpy(), label='Actual', color='blue', alpha=0.6, marker='o', linestyle='None')\n",
    "        plt.plot(predictions.numpy(), label='Predicted', color='orange', alpha=0.6, marker='x', linestyle='None')\n",
    "        plt.legend()\n",
    "        plt.title('Actual vs Predicted')\n",
    "        plt.xlabel('Sample')\n",
    "        plt.ylabel('Sales')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('../results/images/actual_vs_predicted.png')\n",
    "        mlflow.log_artifact('../results/images/actual_vs_predicted.png')\n",
    "\n",
    "        # Residual plot\n",
    "        residuals = y_test.numpy() - predictions.numpy()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(predictions.numpy(), residuals, alpha=0.5, color='purple')\n",
    "        plt.hlines(y=0, xmin=min(predictions.numpy()), xmax=max(predictions.numpy()), colors='r')\n",
    "        plt.title('Residuals Plot')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('../results/images/residuals_plot.png')\n",
    "        mlflow.log_artifact('../results/images/residuals_plot.png')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Distribution of residuals\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        sns.histplot(residuals, kde=True, color='green')\n",
    "        plt.title('Distribution of Residuals')\n",
    "        plt.xlabel('Residuals')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('../results/images/residuals_distribution.png')\n",
    "        mlflow.log_artifact('../results/images/residuals_distribution.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Scatter plot of actual vs predicted\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        plt.scatter(y_test.numpy(), predictions.numpy(), alpha=0.5)\n",
    "        plt.plot([min(y_test.numpy()), max(y_test.numpy())], [min(y_test.numpy()), max(y_test.numpy())], color='red', linestyle='--')\n",
    "        plt.title('Actual vs Predicted Scatter Plot')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('../results/images/actual_vs_predicted_scatter.png')\n",
    "        mlflow.log_artifact('../results/images/actual_vs_predicted_scatter.png')\n",
    "        plt.show()\n",
    "\n",
    "        # Q-Q Plot\n",
    "        plt.figure(figsize=(7, 5))\n",
    "        stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "        plt.title('Q-Q Plot')\n",
    "        plt.grid(True)\n",
    "        plt.savefig('../results/images/qq_plot.png')\n",
    "        mlflow.log_artifact('../results/images/qq_plot.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PhdQbuozqk-"
   },
   "source": [
    "**Summary of Interpretation**\n",
    "\n",
    "**MSE**: 108.9332\n",
    "Indicates the average squared difference between the predicted and actual values is around 108.93. This suggests that there are some large errors in the predictions.\n",
    "\n",
    "**MAE**: 8.1420\n",
    "Indicates that, on average, the model's predictions are off by about 8.14 units. This is easier to interpret and understand compared to MSE.\n",
    "\n",
    "**RMSE**: 10.4371\n",
    "This value is in the same units as the target variable (sales units), indicating that the typical prediction error is about 10.44 units. RMSE penalizes larger errors more than MAE.\n",
    "\n",
    "**R²**: 0.8067\n",
    "Suggests that the model explains about 80.67% of the variance in the sales data, which is quite good. This indicates a strong relationship between the features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xOUamDJRBpzx"
   },
   "outputs": [],
   "source": [
    "run_id = run.info.run_id\n",
    "print(f'Run ID: {run_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
